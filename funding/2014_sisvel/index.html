<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Ph.D. scholarship | francesco verdoja </title> <meta name="author" content="Francesco Verdoja"> <meta name="description" content="3-year full Ph.D. scholarship"> <meta name="keywords" content="robotics, mapping, computer vision, artificial intelligence, ai, machine learning, research, academia"> <meta property="og:site_name" content="francesco verdoja"> <meta property="og:type" content="website"> <meta property="og:title" content="francesco verdoja | Ph.D. scholarship"> <meta property="og:url" content="https://fverdoja.github.io/funding/2014_sisvel/"> <meta property="og:description" content="3-year full Ph.D. scholarship"> <meta property="og:image" content="assets/img/fra.jpg"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="Ph.D. scholarship"> <meta name="twitter:description" content="3-year full Ph.D. scholarship"> <meta name="twitter:image" content="assets/img/fra.jpg"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Francesco Verdoja"
        },
        "url": "https://fverdoja.github.io/funding/2014_sisvel/",
        "@type": "WebSite",
        "description": "3-year full Ph.D. scholarship",
        "headline": "Ph.D. scholarship",
        
        "sameAs": ["https://orcid.org/0000-0002-9551-6186", "https://scholar.google.com/citations?user=3DDM3_kAAAAJ", "https://www.scopus.com/authid/detail.uri?authorId=56685641600", "https://github.com/fverdoja", "https://www.linkedin.com/in/fverdoja", "https://research.aalto.fi/en/persons/francesco-verdoja"],
        
        "name": "Francesco Verdoja",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%94%B8&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://fverdoja.github.io/funding/2014_sisvel/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">francesco</span> verdoja </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">news </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/events/">events </a> </li> <li class="nav-item active"> <a class="nav-link" href="/funding/">funding <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item"><a class="nav-link" href="/assets/pdf/verdoja_francesco.pdf">cv</a></li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Ph.D. scholarship</span> | Segmentation and tracking methods for innovative video compression techniques </h1> <p class="post-description">3-year full Ph.D. scholarship</p> <ul class="post-tags fa-ul"> <li> <span class="fa-li"><i class="fa-solid fa-landmark fa-sm"></i></span><strong>Funded by:</strong> <a href="https://www.sisvel.com/" rel="external nofollow noopener" target="_blank">Sisvel Technology</a> </li> <li> <span class="fa-li"><i class="fa-solid fa-coins fa-sm"></i></span><strong>Budget:</strong> 41k€ </li> <li> <span class="fa-li"><i class="fa-solid fa-calendar fa-sm"></i></span><strong>Period:</strong> Jan 2014–Dec 2016 </li> </ul> </header> <article> <h2 id="abstract">abstract</h2> <p>The first phase of standardization of the brand new MPEG coding technology, HEVC, has just been completed. However, there is a significant need of new coding techniques that can satisfy the requirements of future video applications and services, e.g. ultra high definition and high frame rate content and fully immersive multimedia experiences. Innovative image segmentation and tracking tools are expected to play a significant role in the design of novel compression technologies in the era of ultra-high definition and high frame rate video content.</p> </article> <h2 id="related-publications">related publications</h2> <div class="publications"> <h2 class="bibliography">theses</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/thesis_17-480.webp 480w,/assets/img/publication_preview/thesis_17-800.webp 800w,/assets/img/publication_preview/thesis_17-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/thesis_17.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="thesis_17.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="201707_verdoja_use" class="col-sm-8"> <div class="title">The use of Graph Fourier Transform in image processing: a new solution to classical problems</div> <div class="author"> <em>Francesco Verdoja</em> </div> <div class="periodical"> Jul 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://iris.unito.it/retrieve/handle/2318/1645345/352523/PhdThesis_Verdoja.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Graph-based approaches have recently seen a spike of interest in the image processing and computer vision communities, and many classical problems are finding new solutions thanks to these techniques. The Graph Fourier Transform (GFT), the equivalent of the Fourier transform for graph signals, is used in many domains to analyze and process data modeled by a graph. In this thesis we present some classical image processing problems that can be solved through the use of GFT. We’ll focus our attention on two main research area: the first is image compression, where the use of the GFT is finding its way in recent literature; we’ll propose two novel ways to deal with the problem of graph weight encoding. We’ll also propose approaches to reduce overhead costs of shape-adaptive compression methods. The second research field is image anomaly detection, GFT has never been proposed to this date to solve this class of problems; we’ll discuss here a novel technique and we’ll test its application on hyperspectral and medical images. We’ll show how graph approaches can be used to generalize and improve performance of the widely popular RX Detector, by reducing its computational complexity while at the same time fixing the well known problem of its dependency from covariance matrix estimation and inversion. All our experiments confirm that graph-based approaches leveraging on the GFT can be a viable option to solve tasks in multiple image processing domains.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@phdthesis</span><span class="p">{</span><span class="nl">201707_verdoja_use</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Torino, Italy}</span><span class="p">,</span>
  <span class="na">type</span> <span class="p">=</span> <span class="s">{Doctoral dissertation}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The use of {Graph} {Fourier} {Transform} in image processing: a 
                   new solution to classical problems}</span><span class="p">,</span>
  <span class="na">shorttitle</span> <span class="p">=</span> <span class="s">{The use of {Graph} {Fourier} {Transform} in image processing}</span><span class="p">,</span>
  <span class="na">school</span> <span class="p">=</span> <span class="s">{Università degli Studi di Torino}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Verdoja, Francesco}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">journal articles</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">MVAP</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mvap_20-480.webp 480w,/assets/img/publication_preview/mvap_20-800.webp 800w,/assets/img/publication_preview/mvap_20-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/mvap_20.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mvap_20.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="202001_verdoja_graph" class="col-sm-8"> <div class="title">Graph Laplacian for image anomaly detection</div> <div class="author"> <em>Francesco Verdoja</em>, and Marco Grangetto </div> <div class="periodical"> <em>Machine Vision and Applications</em>, Jan 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/1802.09843" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/content/pdf/10.1007/s00138-020-01059-4.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/fverdoja/LAD-Laplacian-Anomaly-Detector" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Reed-Xiaoli detector (RXD) is recognized as the benchmark algorithm for image anomaly detection; however, it presents known limitations, namely the dependence over the image following a multivariate Gaussian model, the estimation and inversion of a high-dimensional covariance matrix, and the inability to effectively include spatial awareness in its evaluation. In this work, a novel graph-based solution to the image anomaly detection problem is proposed; leveraging the graph Fourier transform, we are able to overcome some of RXD’s limitations while reducing computational cost at the same time. Tests over both hyperspectral and medical images, using both synthetic and real anomalies, prove the proposed technique is able to obtain significant gains over performance by other algorithms in the state of the art.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">202001_verdoja_graph</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Graph {Laplacian} for image anomaly detection}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{31}</span><span class="p">,</span>
  <span class="na">issue</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s00138-020-01059-4}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Machine Vision and Applications}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Verdoja, Francesco and Grangetto, Marco}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">book chapters</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICIAP</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/iciap_15-480.webp 480w,/assets/img/publication_preview/iciap_15-800.webp 800w,/assets/img/publication_preview/iciap_15-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/iciap_15.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="iciap_15.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="201509_verdoja_fast" class="col-sm-8"> <div class="title">Fast Superpixel-Based Hierarchical Approach to Image Segmentation</div> <div class="author"> <em>Francesco Verdoja</em>, and Marco Grangetto </div> <div class="periodical"> <em>In Image Analysis and Processing—ICIAP 2015</em>, Sep 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/content/pdf/10.1007/978-3-319-23231-7_33.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Image segmentation is one of the core task in image processing. Traditionally such operation is performed starting from single pixels requiring a significant amount of computations. Only recently it has been shown that superpixels can be used to improve segmentation performance. In this work we propose a novel superpixel-based hierarchical approach for image segmentation that works by iteratively merging nodes of a weighted undirected graph initialized with the superpixels regions. Proper metrics to drive the regions merging are proposed and experimentally validated using the standard Berkeley Dataset. Our analysis shows that the proposed algorithm runs faster than state of the art techniques while providing accurate segmentation results both in terms of visual and objective metrics.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@incollection</span><span class="p">{</span><span class="nl">201509_verdoja_fast</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Lecture {Notes} in {Computer} {Science}}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fast {Superpixel}-{Based} {Hierarchical} {Approach} to {Image} 
                   {Segmentation}}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{9279}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-23231-7_33}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Image {Analysis} and {Processing}---{ICIAP} 2015}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Verdoja, Francesco and Grangetto, Marco}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{364--374}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">conference articles</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICME</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/icme_17-480.webp 480w,/assets/img/publication_preview/icme_17-800.webp 800w,/assets/img/publication_preview/icme_17-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/icme_17.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icme_17.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="201707_verdoja_fast" class="col-sm-8"> <div class="title">Fast 3D point cloud segmentation using supervoxels with geometry and color for 3D scene understanding</div> <div class="author"> <em>Francesco Verdoja</em>, Diego Thomas, and Akihiro Sugimoto </div> <div class="periodical"> <em>In 2017 IEEE Int. Conf. on Multimedia and Expo (ICME)</em>, Jul 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019382" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/fverdoja/Fast-3D-Pointcloud-Segmentation" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Segmentation of 3D colored point clouds is a research field with renewed interest thanks to recent availability of inexpensive consumer RGB-D cameras and its importance as an unavoidable low-level step in many robotic applications. However, 3D data’s nature makes the task challenging and, thus, many different techniques are being proposed , all of which require expensive computational costs. This paper presents a novel fast method for 3D colored point cloud segmen-tation. It starts with supervoxel partitioning of the cloud, i.e., an oversegmentation of the points in the cloud. Then it leverages on a novel metric exploiting both geometry and color to iteratively merge the supervoxels to obtain a 3D segmentation where the hierarchical structure of partitions is maintained. The algorithm also presents computational complexity linear to the size of the input. Experimental results over two publicly available datasets demonstrate that our proposed method outperforms state-of-the-art techniques.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">201707_verdoja_fast</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Hong Kong}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fast 3D point cloud segmentation using supervoxels with geometry 
                   and color for 3D scene understanding}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICME.2017.8019382}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2017 {IEEE} {Int.}\ {Conf.}\ on {Multimedia} and 
                   {Expo} ({ICME})}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Verdoja, Francesco and Thomas, Diego and Sugimoto, Akihiro}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1285--1290}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICASSP</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/icassp_2_17-480.webp 480w,/assets/img/publication_preview/icassp_2_17-800.webp 800w,/assets/img/publication_preview/icassp_2_17-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/icassp_2_17.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icassp_2_17.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="201703_verdoja_directional" class="col-sm-8"> <div class="title">Directional graph weight prediction for image compression</div> <div class="author"> <em>Francesco Verdoja</em>, and Marco Grangetto </div> <div class="periodical"> <em>In 2017 IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP)</em>, Mar 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7952410" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Graph-based models have recently attracted attention for their potential to enhance transform coding image compression thanks to their capability to efficiently represent discontinuities. Graph transform gets closer to the optimal KLT by using weights that represent inter-pixel correlations but the extra cost to provide such weights can overwhelm the gain, especially in the case of natural images rich of details. In this paper we provide a novel idea to make graph transform adaptive to the actual image content, avoiding the need to encode the graph weights as side information. We show that an approach similar to spatial prediction can be used to effectively predict graph weights in place of pixels; in particular, we propose the design of directional graph weight prediction modes and show the resulting coding gain. The proposed approach can be used jointly with other graph based intra prediction methods to further enhance compression. Our comparative experimental analysis, carried out with a fully fledged still image coding prototype, shows that we are able to achieve significant coding gains.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">201703_verdoja_directional</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New Orleans, LA}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Directional graph weight prediction for image compression}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICASSP.2017.7952410}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2017 {IEEE} {Int.}\ {Conf.}\ on {Acoustics}, 
                   {Speech} and {Signal} {Processing} ({ICASSP})}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Verdoja, Francesco and Grangetto, Marco}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1517--1521}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICASSP</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/icassp_1_17-480.webp 480w,/assets/img/publication_preview/icassp_1_17-800.webp 800w,/assets/img/publication_preview/icassp_1_17-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/icassp_1_17.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icassp_1_17.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="201703_verdoja_efficient" class="col-sm-8"> <div class="title">Efficient representation of segmentation contours using chain codes</div> <div class="author"> <em>Francesco Verdoja</em>, and Marco Grangetto </div> <div class="periodical"> <em>In 2017 IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP)</em>, Mar 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7952399" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Segmentation is one of the most important low-level tasks in image processing as it enables many higher level computer vision tasks like object recognition and tracking. Segmentation can also be exploited for image compression using recent graph-based algorithms, provided that the corresponding contours can be represented efficiently. Transmission of borders is also key to distributed computer vision. In this paper we propose a new chain code tailored to compress segmentation contours. Based on the widely known 3OT, our algorithm is able to encode regions avoiding borders it has already coded once and without the need of any starting point information for each region. We tested our method against three other state of the art chain codes over the BSDS500 dataset, and we demonstrated that the proposed chain code achieves the highest compression ratio, resulting on average in over 27% bit-per-pixel saving.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">201703_verdoja_efficient</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New Orleans, LA}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Efficient representation of segmentation contours using chain 
                   codes}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICASSP.2017.7952399}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2017 {IEEE} {Int.}\ {Conf.}\ on {Acoustics}, 
                   {Speech} and {Signal} {Processing} ({ICASSP})}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Verdoja, Francesco and Grangetto, Marco}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1462--1466}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICIP</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/icip_15-480.webp 480w,/assets/img/publication_preview/icip_15-800.webp 800w,/assets/img/publication_preview/icip_15-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/icip_15.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icip_15.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="201509_fracastoro_superpixel-driven" class="col-sm-8"> <div class="title">Superpixel-driven Graph Transform for Image Compression</div> <div class="author"> Giulia Fracastoro, <em>Francesco Verdoja</em>, Marco Grangetto, and Enrico Magli </div> <div class="periodical"> <em>In 2015 IEEE Int. Conf. on Image Processing (ICIP)</em>, Sep 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Best 10% Paper</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://iris.unito.it/bitstream/2318/1557609/2/articleICIP15.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Awarded at the 2015 IEEE Int. Conf. on Image Processing (ICIP)</p> </div> <div class="abstract hidden"> <p>Block-based compression tends to be inefficient when blocks contain arbitrary shaped discontinuities. Recently, graph-based approaches have been proposed to address this issue, but the cost of transmitting graph topology often overcome the gain of such techniques. In this work we propose a new Superpixel-driven Graph Transform (SDGT) that uses clusters of superpixels, which have the ability to adhere nicely to edges in the image, as coding blocks and computes inside these homogeneously colored regions a graph transform which is shape-adaptive. Doing so, only the borders of the regions and the transform coefficients need to be transmitted, in place of all the structure of the graph. The proposed method is finally compared to DCT and the experimental results show how it is able to outperform DCT both visually and in term of PSNR.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">201509_fracastoro_superpixel-driven</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Quebec City, Canada}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Superpixel-driven {Graph} {Transform} for {Image} {Compression}}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICIP.2015.7351279}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2015 {IEEE} {Int.}\ {Conf.}\ on {Image} 
                   {Processing} ({ICIP})}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fracastoro, Giulia and Verdoja, Francesco and Grangetto, Marco and Magli, Enrico}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2631--2635}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">patents</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/patent_2_18-480.webp 480w,/assets/img/publication_preview/patent_2_18-800.webp 800w,/assets/img/publication_preview/patent_2_18-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/patent_2_18.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="patent_2_18.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="201809_grangetto_method" class="col-sm-8"> <div class="title">Method and Apparatus for Encoding and Decoding Digital Images or Video Streams</div> <div class="author"> Marco Grangetto, and <em>Francesco Verdoja</em> </div> <div class="periodical"> Sep 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://patentimages.storage.googleapis.com/22/35/dc/d31d103dd9f3dd/US20200014955A1.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>A method for encoding digital images or video streams, includes a receiving phase, wherein a portion of an image is received; a graph weights prediction phase, wherein the elements of a weights matrix associated to the graph related to the blocks of the image (predicted blocks) are predicted on the basis of reconstructed, de-quantized and inverse-transformed pixel values of at least one previously coded block (predictor block) of the image, the weights matrix being a matrix comprising elements denoting the level of similarity between a pair of pixels composing said image, a graph transform computation phase, wherein the graph Fourier transform of the blocks of the image is performed, obtaining for the blocks a set of coefficients determined on the basis of the predicted weights; a coefficients quantization phase, wherein the coefficients are quantized an output phase wherein a bitstream comprising the transformed and quantized coefficients is transmitted and/or stored.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@patent</span><span class="p">{</span><span class="nl">201809_grangetto_method</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Method and {Apparatus} for {Encoding} and {Decoding} {Digital} 
                   {Images} or {Video} {Streams}}</span><span class="p">,</span>
  <span class="na">assignee</span> <span class="p">=</span> <span class="s">{Sisvel Technology S.r.l}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{WO2018158735 (A1)}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Grangetto, Marco and Verdoja, Francesco}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/patent_1_18-480.webp 480w,/assets/img/publication_preview/patent_1_18-800.webp 800w,/assets/img/publication_preview/patent_1_18-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/patent_1_18.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="patent_1_18.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="201809_grangetto_methods" class="col-sm-8"> <div class="title">Methods and Apparatuses for Encoding and Decoding Superpixel Borders</div> <div class="author"> Marco Grangetto, and <em>Francesco Verdoja</em> </div> <div class="periodical"> Sep 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://patentimages.storage.googleapis.com/f2/f7/12/50250a322ba55b/US10708601.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>The present invention relates to a method for encoding the borders of pixel regions of an image, wherein the borders contain a sequence of vertices subdividing the image into regions of pixels (superpixels), by generating a sequence of symbols from an alphabet including the step of: defining for each superpixel a first vertex for coding the borders of the superpixel according to a criterion common to all superpixels; defining for each superpixel the same coding order of the border vertices, either clockwise or counter-clockwise; defining the order for coding the superpixels on the base of a common rule depending on the relative positions of the first vertices; defining a set of vertices as a known border, wherein the following steps are performed for selecting a symbol of the alphabet, for encoding the borders of the superpixels: a) determining the first vertex of the next superpixel border individuated by the common criterion; b) determining the next vertex to be encoded on the basis of the coding direction; c) selecting a first symbol (“0”) for encoding the next vertex if the next vertex of a border pertains to the known border, d) selecting a symbol (“1”; “2”) different from the first symbol (“0”) if the next vertex is not in the known border; e) repeating steps b), c), d) and e) until all vertices of the superpixel border have been encoded; f) adding each vertex of the superpixel border that was not in the known border to the set; g) determining the next superpixel whose border is to be encoded according to the common rule, if any; i) repeating steps a)-g) until the borders of all the superpixels of the image have being added to the known border.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@patent</span><span class="p">{</span><span class="nl">201809_grangetto_methods</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Methods and {Apparatuses} for {Encoding} and {Decoding} 
                   {Superpixel} {Borders}}</span><span class="p">,</span>
  <span class="na">assignee</span> <span class="p">=</span> <span class="s">{Sisvel Technology S.r.l}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{WO2018158738 (A1)}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Grangetto, Marco and Verdoja, Francesco}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/patent_17-480.webp 480w,/assets/img/publication_preview/patent_17-800.webp 800w,/assets/img/publication_preview/patent_17-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/patent_17.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="patent_17.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="201703_fracastoro_methods" class="col-sm-8"> <div class="title">Methods and Apparatuses for Encoding and Decoding Digital Images Through Superpixels</div> <div class="author"> Giulia Fracastoro, Enrico Magli, <em>Francesco Verdoja</em>, and Marco Grangetto </div> <div class="periodical"> Mar 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://patentimages.storage.googleapis.com/f4/8a/16/bab6bd298dea8d/US20180278957A1.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>A method and an apparatus for encoding and/or decoding digital images or video streams are provided, wherein the encoding apparatus includes a processor configured for reading at least a portion of the image, segmenting the portion of the image in order to obtain groups of pixels identified by borders information and containing at least two pixels having one or more homogeneous characteristics, computing, for each group of pixels, a weight map on the basis of the borders information associated to the group of pixels, a graph transform matrix on the basis of the weight map, and transform coefficients on the basis of the graph transform matrix (U) and of the pixels contained in the group of pixels.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@patent</span><span class="p">{</span><span class="nl">201703_fracastoro_methods</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Methods and {Apparatuses} for {Encoding} and {Decoding} {Digital} 
                   {Images} {Through} {Superpixels}}</span><span class="p">,</span>
  <span class="na">assignee</span> <span class="p">=</span> <span class="s">{Sisvel Technology Srl; Politecnico Di Torino}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{WO2017051358 (A1)}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fracastoro, Giulia and Magli, Enrico and Verdoja, Francesco and Grangetto, Marco}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Francesco Verdoja. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: September 23, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>